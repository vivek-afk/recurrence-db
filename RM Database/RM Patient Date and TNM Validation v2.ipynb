{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting number patients: 364\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "file_name='RM_ptx_information.csv'\n",
    "df=pd.read_csv(file_name)\n",
    "cols=['MRN','stage','Treatment 1 Date of Progression','IRB']\n",
    "df=df[cols]\n",
    "#df=df[df['IRB']=='8980']\n",
    "print ('starting number patients:',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrns with stage: 154\n",
      "       Stage\n",
      "MRN         \n",
      "654028   IVA\n",
      "656036   IVA\n",
      "724115   IVA\n",
      "765010   IVB\n",
      "788213   IVA\n",
      "all notes are int\n",
      "number of mrns at start: 7415\n",
      "Num of patients: 128\n",
      "        Stage_\n",
      "MRN           \n",
      "2050963    IVA\n",
      "2460803     II\n",
      "2209904    IVA\n",
      "3535060    III\n",
      "3447609    IVA\n",
      "size of merged df: 273 \n",
      "\n",
      "complete entries: 9\n",
      "[4 4 4 4 4 3 4 4 4]\n",
      "[3 4 4 4 4 4 4 2 3]\n",
      "Accuracy: 0.56\n",
      "Cohen's Kappa: -0.16\n"
     ]
    }
   ],
   "source": [
    "### First validate stage - prepare validation cohort\n",
    "def isGoodStage(stage):\n",
    "    try:\n",
    "        good_stages=['I','II','III','IVA','IVB','IVC']\n",
    "        if stage in good_stages:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "df_holdout=df[df.stage.apply(isGoodStage)]\n",
    "df_holdout=df_holdout[['MRN','stage']]\n",
    "df_holdout.columns=['MRN','Stage']\n",
    "df_holdout=df_holdout.set_index('MRN')\n",
    "print ('mrns with stage:',df_holdout.shape[0])\n",
    "print (df_holdout.head())\n",
    "\n",
    "### prepare stages from notes\n",
    "### divide up groups by TNM Staging\n",
    "df_notes=pd.read_csv('HNDB Progress Notes Processed.csv')\n",
    "cols_to_keep=['mrn','Cancer_stage']\n",
    "df_notes=df_notes[cols_to_keep]\n",
    "df_notes.columns=['MRN','Stage_']\n",
    "# get rid of notes that have a string as an MRN\n",
    "try:\n",
    "    df_notes=df_notes[df_notes['MRN'].str.isnumeric()]\n",
    "except:\n",
    "    print('all notes are int')\n",
    "\n",
    "print('number of mrns at start:',df_notes.shape[0])\n",
    "df_notes=df_notes.dropna(subset=['MRN','Stage_'])\n",
    "# a little formatting, as a treat\n",
    "df_notes['MRN']=df_notes['MRN'].astype(int)\n",
    "df_notes.Stage_=df_notes.Stage_.str.upper()\n",
    "# start making df\n",
    "unique_mrns=df_notes.MRN.unique()\n",
    "#create list of dataframes - each represents an mrn\n",
    "ptx_info=[]\n",
    "for mrn in unique_mrns:\n",
    "    df_sub=df_notes[df_notes.MRN==mrn]\n",
    "    ptx_info.append(df_sub)\n",
    "print ('Num of patients:',len(ptx_info))\n",
    "data=[]\n",
    "for index,ptx in enumerate(ptx_info):\n",
    "    data.append([ptx.iloc[0]['MRN'],ptx.iloc[-1]['Stage_']])\n",
    "df_notes=pd.DataFrame(data,columns=['MRN','Stage_'])\n",
    "df_notes.MRN=df_notes.MRN.apply(pd.to_numeric)\n",
    "df_notes=df_notes.set_index('MRN')\n",
    "\n",
    "print (df_notes.head())\n",
    "\n",
    "### merge dataframes\n",
    "# merge dfs\n",
    "df_merged = pd.merge(df_holdout, df_notes, on='MRN',how='outer')\n",
    "print ('size of merged df:',df_merged.shape[0],'\\n')\n",
    "\n",
    "df_val=df_merged.dropna(subset=['Stage','Stage_'],how='any')\n",
    "#df_val.to_csv('examine.csv')\n",
    "print ('complete entries:',df_val.shape[0])\n",
    "\n",
    "#calculate cohen's kappa\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "cat_map={'I':1,'II':2,'III':3,'IVA':4,'IVB':5,'IVC':6}\n",
    "\n",
    "note_stages=df_val.Stage_.map(cat_map).to_numpy(dtype=int)\n",
    "val_stages=df_val.Stage.map(cat_map).to_numpy(dtype=int)\n",
    "\n",
    "print (note_stages)\n",
    "print (val_stages)\n",
    "\n",
    "score=cohen_kappa_score(note_stages,val_stages)\n",
    "\n",
    "# calculate accuracy\n",
    "total_ptx=df_val.shape[0]\n",
    "matches=0\n",
    "for index,row in df_val.iterrows():\n",
    "    if row['Stage']==row['Stage_']:\n",
    "        matches=matches+1\n",
    "accuracy=matches/total_ptx\n",
    "\n",
    "print ('Accuracy:',round(accuracy,2))\n",
    "print ('Cohen\\'s Kappa:',round(score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val df - starting number patients: 364\n",
      "patients with date_DM 282\n"
     ]
    }
   ],
   "source": [
    "### now do date_DM - prepare validation set\n",
    "file_name='RM_ptx_information.csv'\n",
    "df=pd.read_csv(file_name)\n",
    "cols=['MRN','Treatment 1 Date of Progression','IRB']\n",
    "df=df[cols]\n",
    "#df=df[df['IRB']=='8980']\n",
    "cols=['MRN','Treatment 1 Date of Progression']\n",
    "df=df[cols]\n",
    "df.columns=['MRN','Date_DM']\n",
    "print ('val df - starting number patients:',df.shape[0])\n",
    "def process_dates(sent):\n",
    "    try:\n",
    "        search=re.search(r'\\d',sent)\n",
    "        if not search:\n",
    "            return np.nan\n",
    "        toReturn=sent\n",
    "        if ' ' in sent:\n",
    "            toReturn=toReturn.split(' ')[0]\n",
    "        if ',' in sent:\n",
    "            toReturn=toReturn.split(',')[0]\n",
    "        if ';' in sent:\n",
    "            toReturn=toReturn.split(';')[0]\n",
    "        if '.' in sent:\n",
    "            toReturn=toReturn.replace('.','/')\n",
    "        return toReturn\n",
    "    except:\n",
    "        return np.nan\n",
    "df['Date_DM']=df['Date_DM'].apply(process_dates)\n",
    "df=df.dropna(subset=['Date_DM'])\n",
    "\n",
    "df['Date_DM']=pd.to_datetime(df['Date_DM'], infer_datetime_format=True,errors='coerce') \n",
    "mrns_val=df.MRN.unique()\n",
    "df=df.set_index('MRN')\n",
    "print ('patients with date_DM',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### for new csv_df 20200723\n",
    "# df=pd.read_csv('UC_recurrent_mrns.csv')\n",
    "# print (df.columns)\n",
    "# cols=['MRN','Date of Progression']\n",
    "# df=df[cols]\n",
    "# try:\n",
    "#     df.MRN=df.MRN.str.replace('-','')\n",
    "#     df.MRN=df.MRN.astype('int64')\n",
    "# except:\n",
    "#     print('mrns are already in correct form')\n",
    "# df.columns=['MRN','Date_DM']\n",
    "# df['Date_DM']=pd.to_datetime(df['Date_DM'], infer_datetime_format=True,errors='coerce') \n",
    "# df=df.set_index('MRN')\n",
    "# df=df.dropna(subset=['Date_DM'])\n",
    "# print ('patients with date_DM',df.shape[0])\n",
    "\n",
    "# print (df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrns in both the notes and the val df: 73\n",
      "patients in notes: 171\n",
      "patients with Date_DM: 142\n",
      "          Date_DM_\n",
      "MRN               \n",
      "2050963 2014-10-01\n",
      "2460803 1999-04-01\n",
      "2714226 2000-02-01\n",
      "2209904 2000-09-08\n",
      "3535060 2016-03-01\n",
      "...            ...\n",
      "3108147 2018-05-08\n",
      "3769590 2018-08-07\n",
      "3749634 2018-06-08\n",
      "3793494 2018-07-13\n",
      "3715744 2018-07-17\n",
      "\n",
      "[142 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "### get Date_RM_ from notes\n",
    "df_notes=pd.read_csv('RM_MCs.csv',parse_dates=True)\n",
    "df_notes.columns=['Date','MRN','is_RM']\n",
    "df_notes['Date']=pd.to_datetime(df_notes['Date'], infer_datetime_format=True,errors='coerce')\n",
    "\n",
    "### compare overlap of mrns\n",
    "mrns_notes=df_notes.MRN.unique()\n",
    "count=0\n",
    "for mrn in mrns_notes:\n",
    "    if mrn in mrns_val:\n",
    "        count+=1\n",
    "print ('mrns in both the notes and the val df:',count)\n",
    "\n",
    "\n",
    "unique_mrns=df_notes.MRN.unique()\n",
    "print ('patients in notes:',len(unique_mrns))\n",
    "#create list of dataframes - each represents an mrn\n",
    "ptx_info=[]\n",
    "for mrn in unique_mrns:\n",
    "    df_sub=df_notes[df_notes.MRN==mrn]\n",
    "    ptx_info.append(df_sub)\n",
    "data=[]\n",
    "date_earliest=[]\n",
    "for i,ptx in enumerate(ptx_info):\n",
    "    date=np.nan\n",
    "    mrn=ptx.iloc[0]['MRN']\n",
    "    date_earliest.append([mrn, ptx.iloc[0]['Date']])\n",
    "    tripped=False\n",
    "    for index,row in ptx.iterrows():\n",
    "        if not tripped:\n",
    "            if row['is_RM']==1:\n",
    "                date=row['Date']\n",
    "                tripped=True\n",
    "    data.append([mrn,date])\n",
    "df_notes=pd.DataFrame(data, columns=['MRN','Date_DM_'])\n",
    "df_notes=df_notes.dropna(subset=['Date_DM_'])\n",
    "df_notes=df_notes.set_index('MRN')\n",
    "print ('patients with Date_DM:',df_notes.shape[0])\n",
    "print (df_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients with info: 57\n",
      "MRN\t\tValidated Date\t\tDate from notes\t\tDiff\t\tEarliest Note\n",
      "1420705 \t 2007-02-26 00:00:00 \t 2009-10-28 00:00:00 : -975 days +00:00:00 \t 2009-10-28 00:00:00\n",
      "1504532 \t 2018-01-19 00:00:00 \t 2014-10-28 00:00:00 : 1179 days 00:00:00 \t 2011-04-16 00:00:00\n",
      "1566343 \t 2012-08-11 00:00:00 \t 2012-08-11 00:00:00 : 0 days 00:00:00 \t 2012-04-01 00:00:00\n",
      "1868643 \t 2013-03-22 00:00:00 \t 2012-04-06 00:00:00 : 350 days 00:00:00 \t 2012-04-01 00:00:00\n",
      "1868643 \t 2013-03-22 00:00:00 \t 2012-04-06 00:00:00 : 350 days 00:00:00 \t 2012-04-01 00:00:00\n",
      "2050963 \t 2015-10-02 00:00:00 \t 2014-10-01 00:00:00 : 366 days 00:00:00 \t 1996-02-26 00:00:00\n",
      "2573707 \t 2002-12-18 00:00:00 \t 2012-08-28 00:00:00 : -3541 days +00:00:00 \t 2010-08-25 00:00:00\n",
      "2849915 \t 2006-12-14 00:00:00 \t 2007-01-01 00:00:00 : -18 days +00:00:00 \t 2007-01-01 00:00:00\n",
      "2913559 \t 2007-08-07 00:00:00 \t 2012-05-21 00:00:00 : -1749 days +00:00:00 \t 2012-05-21 00:00:00\n",
      "2933746 \t 2009-05-14 00:00:00 \t 2009-06-17 00:00:00 : -34 days +00:00:00 \t 2007-03-02 00:00:00\n",
      "2958683 \t 2011-02-11 00:00:00 \t 2012-07-12 00:00:00 : -517 days +00:00:00 \t 2011-03-05 00:00:00\n",
      "2975703 \t 2009-02-10 00:00:00 \t 2008-09-01 00:00:00 : 162 days 00:00:00 \t 2008-09-01 00:00:00\n",
      "2979285 \t 2007-11-05 00:00:00 \t 2012-07-02 00:00:00 : -1701 days +00:00:00 \t 2008-01-12 00:00:00\n",
      "3028615 \t 2010-03-03 00:00:00 \t 2013-07-26 00:00:00 : -1241 days +00:00:00 \t 2013-07-26 00:00:00\n",
      "3054505 \t 2008-06-16 00:00:00 \t 2012-08-21 00:00:00 : -1527 days +00:00:00 \t 2008-03-01 00:00:00\n",
      "3123549 \t 2010-05-19 00:00:00 \t 2010-05-19 00:00:00 : 0 days 00:00:00 \t 2010-02-03 00:00:00\n",
      "3134848 \t 2010-12-06 00:00:00 \t 2012-05-09 00:00:00 : -520 days +00:00:00 \t 2012-05-09 00:00:00\n",
      "3148181 \t 2010-12-17 00:00:00 \t 2010-11-05 00:00:00 : 42 days 00:00:00 \t 2010-11-05 00:00:00\n",
      "3151830 \t 2016-03-01 00:00:00 \t 2016-04-03 00:00:00 : -33 days +00:00:00 \t 2011-01-01 00:00:00\n",
      "3156002 \t 2011-02-11 00:00:00 \t 2011-03-01 00:00:00 : -18 days +00:00:00 \t 2010-11-01 00:00:00\n",
      "3165977 \t 2014-02-27 00:00:00 \t 2014-01-08 00:00:00 : 50 days 00:00:00 \t 2010-09-01 00:00:00\n",
      "3171632 \t 2011-09-12 00:00:00 \t 2012-05-08 00:00:00 : -239 days +00:00:00 \t 2012-05-08 00:00:00\n",
      "3191617 \t 2011-09-20 00:00:00 \t 2012-05-24 00:00:00 : -247 days +00:00:00 \t 2011-07-22 00:00:00\n",
      "3192729 \t 2011-11-18 00:00:00 \t 2011-09-01 00:00:00 : 78 days 00:00:00 \t 2011-09-01 00:00:00\n",
      "3199771 \t 2013-05-02 00:00:00 \t 2012-07-05 00:00:00 : 301 days 00:00:00 \t 2011-08-01 00:00:00\n",
      "3221015 \t 2012-09-20 00:00:00 \t 2013-01-23 00:00:00 : -125 days +00:00:00 \t 2011-09-16 00:00:00\n",
      "3232866 \t 2012-06-26 00:00:00 \t 2012-09-08 00:00:00 : -74 days +00:00:00 \t 2012-05-21 00:00:00\n",
      "3244910 \t 2012-02-13 00:00:00 \t 2012-03-20 00:00:00 : -36 days +00:00:00 \t 2011-07-01 00:00:00\n",
      "3249882 \t 2012-01-31 00:00:00 \t 2012-02-28 00:00:00 : -28 days +00:00:00 \t 2011-04-29 00:00:00\n",
      "3251064 \t 2012-10-19 00:00:00 \t 2012-05-23 00:00:00 : 149 days 00:00:00 \t 2012-03-06 00:00:00\n",
      "3259252 \t 2014-08-05 00:00:00 \t 2012-09-05 00:00:00 : 699 days 00:00:00 \t 2012-03-01 00:00:00\n",
      "3260592 \t 2013-12-31 00:00:00 \t 2014-03-13 00:00:00 : -72 days +00:00:00 \t 2012-02-01 00:00:00\n",
      "3261049 \t 2012-11-27 00:00:00 \t 2013-01-11 00:00:00 : -45 days +00:00:00 \t 2012-06-29 00:00:00\n",
      "3276187 \t 2013-10-30 00:00:00 \t 2013-12-03 00:00:00 : -34 days +00:00:00 \t 2012-08-03 00:00:00\n",
      "3279359 \t 2013-07-02 00:00:00 \t 2013-02-15 00:00:00 : 137 days 00:00:00 \t 2012-08-20 00:00:00\n",
      "3301890 \t 2013-10-28 00:00:00 \t 2013-09-01 00:00:00 : 57 days 00:00:00 \t 2012-11-01 00:00:00\n",
      "3307560 \t 2016-04-08 00:00:00 \t 2012-12-31 00:00:00 : 1194 days 00:00:00 \t 2011-12-01 00:00:00\n",
      "3331397 \t 2013-12-17 00:00:00 \t 2014-06-03 00:00:00 : -168 days +00:00:00 \t 2013-05-01 00:00:00\n",
      "3345169 \t 2012-12-21 00:00:00 \t 2011-12-01 00:00:00 : 386 days 00:00:00 \t 2011-04-01 00:00:00\n",
      "3351851 \t 2015-09-08 00:00:00 \t 2013-10-01 00:00:00 : 707 days 00:00:00 \t 2013-10-01 00:00:00\n",
      "3361810 \t 2014-07-15 00:00:00 \t 2014-01-09 00:00:00 : 187 days 00:00:00 \t 2014-01-09 00:00:00\n",
      "3375948 \t 2014-08-22 00:00:00 \t 2014-02-10 00:00:00 : 193 days 00:00:00 \t 2013-07-01 00:00:00\n",
      "3382796 \t 2009-12-31 00:00:00 \t 2009-12-31 00:00:00 : 0 days 00:00:00 \t 2006-05-01 00:00:00\n",
      "3382952 \t 2013-12-16 00:00:00 \t 2014-02-07 00:00:00 : -53 days +00:00:00 \t 2013-05-01 00:00:00\n",
      "3385495 \t 2013-08-27 00:00:00 \t 2013-06-06 00:00:00 : 82 days 00:00:00 \t 2012-11-01 00:00:00\n",
      "3390635 \t 2013-08-13 00:00:00 \t 2014-06-11 00:00:00 : -302 days +00:00:00 \t 2014-06-11 00:00:00\n",
      "3421057 \t 2015-06-16 00:00:00 \t 2015-04-14 00:00:00 : 63 days 00:00:00 \t 2014-08-28 00:00:00\n",
      "3423189 \t 2012-08-30 00:00:00 \t 2014-09-23 00:00:00 : -754 days +00:00:00 \t 2010-03-01 00:00:00\n",
      "3447609 \t 2015-02-06 00:00:00 \t 2015-02-06 00:00:00 : 0 days 00:00:00 \t 2005-11-01 00:00:00\n",
      "3448959 \t 2014-11-14 00:00:00 \t 2014-11-14 00:00:00 : 0 days 00:00:00 \t 2013-07-03 00:00:00\n",
      "3452129 \t 2014-09-12 00:00:00 \t 2014-09-23 00:00:00 : -11 days +00:00:00 \t 2012-02-09 00:00:00\n",
      "3470980 \t 2014-07-28 00:00:00 \t 2014-10-01 00:00:00 : -65 days +00:00:00 \t 2014-06-01 00:00:00\n",
      "3496132 \t 2015-08-19 00:00:00 \t 2015-10-21 00:00:00 : -63 days +00:00:00 \t 2015-10-21 00:00:00\n",
      "3513634 \t 2017-01-11 00:00:00 \t 2016-01-19 00:00:00 : 358 days 00:00:00 \t 2015-01-25 00:00:00\n",
      "3543765 \t 2016-08-23 00:00:00 \t 2016-06-17 00:00:00 : 67 days 00:00:00 \t 2016-04-01 00:00:00\n",
      "3546446 \t 2016-05-25 00:00:00 \t 2015-09-28 00:00:00 : 240 days 00:00:00 \t 2014-08-01 00:00:00\n",
      "3667934 \t 2016-10-13 00:00:00 \t 2016-10-01 00:00:00 : 12 days 00:00:00 \t 2015-12-01 00:00:00\n",
      "count     57.000000\n",
      "mean      12.630994\n",
      "std       20.555354\n",
      "min        0.000000\n",
      "25%        1.400000\n",
      "50%        4.566667\n",
      "75%       12.200000\n",
      "max      118.033333\n",
      "Name: diff, dtype: float64\n",
      "count    46.000000\n",
      "mean      7.777536\n",
      "std      11.443105\n",
      "min       0.000000\n",
      "25%       1.150000\n",
      "50%       2.533333\n",
      "75%       9.583333\n",
      "max      50.900000\n",
      "Name: diff, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# merge dataframes\n",
    "df_merged = pd.merge(df, df_notes, on='MRN',how='inner')\n",
    "df_merged=df_merged.dropna(subset=['Date_DM','Date_DM_'])\n",
    "print ('patients with info:',df_merged.shape[0])\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "def getDateDiff(date1,date2):\n",
    "    diff=date1-date2\n",
    "    return diff\n",
    "diffs=[]\n",
    "oldest_dates=[]\n",
    "print('MRN\\t\\tValidated Date\\t\\tDate from notes\\t\\tDiff\\t\\tEarliest Note')\n",
    "for index,row in df_merged.iterrows():\n",
    "    diff=getDateDiff(row['Date_DM'],row['Date_DM_'])\n",
    "    diffs.append(diff)\n",
    "    earliest=''\n",
    "    for l in date_earliest:\n",
    "        if index==l[0]:\n",
    "            earliest=l[1]\n",
    "            oldest_dates.append(earliest)\n",
    "    print (index,'\\t',row['Date_DM'],'\\t',row['Date_DM_'],':',diff,'\\t',earliest)\n",
    "df_merged['diff']=diffs\n",
    "df_merged['diff']=df_merged['diff'].abs()\n",
    "df_merged['oldest_date']=oldest_dates\n",
    "df_merged['diff']=df_merged['diff'].dt.days/30\n",
    "print(df_merged['diff'].describe())\n",
    "df_merged=df_merged.loc[df_merged['Date_DM']>=df_merged['oldest_date']]\n",
    "#df_merged=df_merged.loc[df_merged['Date_DM']>='2011']\n",
    "\n",
    "print(df_merged['diff'].describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
